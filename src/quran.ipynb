{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "from tashkeel import Tashkeels\n",
    "from check_status import is_jarr\n",
    "\n",
    "def tashkeel_remover(word) :\n",
    "    tokenizer = RegexpTokenizer('[ء-ي]')\n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    word_no_tashkeel = ''.join(tokens)\n",
    "    return(word_no_tashkeel) \n",
    "\n",
    "quran = pd.read_csv('src/Arabic-Original.csv', sep='|',index_col=False, names=['surah', 'verse', 'ayah'], encoding=\"utf-8\" )\n",
    "quran['tokinized_text'] = [ i.split(' ') for i in quran['ayah']]\n",
    "quran['text_no_tashkeel'] = [[tashkeel_remover(word) for word in ayah]for ayah in quran['tokinized_text']]\n",
    "quran['clean_text'] = quran['text_no_tashkeel'].apply(lambda i : ' '.join(i))\n",
    "\n",
    "quran = quran.loc[quran['surah'] == 2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surah</th>\n",
       "      <th>verse</th>\n",
       "      <th>ayah</th>\n",
       "      <th>tokinized_text</th>\n",
       "      <th>text_no_tashkeel</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>فَأَزَلَّهُمَا الشَّيْطَانُ عَنْهَا فَأَخْرَجَ...</td>\n",
       "      <td>[فَأَزَلَّهُمَا, الشَّيْطَانُ, عَنْهَا, فَأَخْ...</td>\n",
       "      <td>[فأزلهما, الشيطان, عنها, فأخرجهما, مما, كانا, ...</td>\n",
       "      <td>فأزلهما الشيطان عنها فأخرجهما مما كانا فيه  وق...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    surah  verse                                               ayah  \\\n",
       "42      2     36  فَأَزَلَّهُمَا الشَّيْطَانُ عَنْهَا فَأَخْرَجَ...   \n",
       "\n",
       "                                       tokinized_text  \\\n",
       "42  [فَأَزَلَّهُمَا, الشَّيْطَانُ, عَنْهَا, فَأَخْ...   \n",
       "\n",
       "                                     text_no_tashkeel  \\\n",
       "42  [فأزلهما, الشيطان, عنها, فأخرجهما, مما, كانا, ...   \n",
       "\n",
       "                                           clean_text  \n",
       "42  فأزلهما الشيطان عنها فأخرجهما مما كانا فيه  وق...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['فَأَزَلَّهُمَا', 'الشَّيْطَانُ', 'عَنْهَا', 'فَأَخْرَجَهُمَا', 'مِمَّا', 'كَانَا', 'فِيهِ', 'ۖ', 'وَقُلْنَا', 'اهْبِطُوا', 'بَعْضُكُمْ', 'لِبَعْضٍ', 'عَدُوٌّ', 'ۖ', 'وَلَكُمْ', 'فِي', 'الْأَرْضِ', 'مُسْتَقَرٌّ', 'وَمَتَاعٌ', 'إِلَىٰ', 'حِينٍ']\n",
      "['فِيهِ', 'فِي']\n",
      "[(6, 'فِيهِ'), (15, 'فِي')]\n",
      "Harf of فِيهِ: the pronoun attatched is هِ - is jarr: True\n",
      "Harf of فِي: the harf is الْأَرْضِ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surah</th>\n",
       "      <th>ayah</th>\n",
       "      <th>jarr</th>\n",
       "      <th>haroof</th>\n",
       "      <th>haroof_is_jarr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>فِي</td>\n",
       "      <td>الْأَرْضِ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  surah ayah jarr     haroof haroof_is_jarr\n",
       "0     2    3  فِي  الْأَرْضِ           True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample value to search for within the lists\n",
    "harf_fi = \"فِي\"\n",
    "\n",
    "# Using DataFrame's `.apply()` method with a custom lambda function\n",
    "result_df = quran[quran['tokinized_text'].apply(lambda x: harf_fi in x)]\n",
    "\n",
    "\n",
    "result_df.to_csv(\"bakara.csv\", sep=',', encoding='utf-8')\n",
    "\n",
    "\n",
    "display(result_df[result_df[\"verse\"]== 36])\n",
    "cell_value = result_df.at[42, 'tokinized_text']\n",
    "print(cell_value)\n",
    "\n",
    "fi_in_ayah = list(filter(lambda item: harf_fi in item, cell_value))\n",
    "result_list_with_indices = list(filter(lambda x: harf_fi in x[1], enumerate(cell_value)))\n",
    "\n",
    "print(fi_in_ayah)\n",
    "print(result_list_with_indices)\n",
    "\n",
    "hoj_df = pd.DataFrame(columns = ['surah', 'ayah', 'jarr', 'haroof', 'haroof_is_jarr'])\n",
    "\n",
    "surah = 2\n",
    "for fi in result_list_with_indices:\n",
    "    \n",
    "    if fi[1] == harf_fi:\n",
    "        print(f\"Harf of {fi[1]}: the harf is {cell_value[fi[0]+1]}\")\n",
    "        row = {'surah': surah, 'ayah':3, 'jarr': fi[1], 'haroof': cell_value[fi[0]+1], 'haroof_is_jarr': is_jarr(cell_value[fi[0]+1])}\n",
    "        hoj_df = pd.concat([hoj_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        pronoun = fi[1].split(harf_fi, 1)[-1].lstrip()\n",
    "        print(f\"Harf of {fi[1]}: the pronoun attatched is {pronoun} - is jarr: {is_jarr(fi[1])}\")\n",
    "\n",
    "display(hoj_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# find all instances of fi in tokenised list per row (each list/ayah may have multiple occurences of fi)\n",
    "# find the work after it\n",
    "# if it ends with kasra = store\n",
    "# if it ends with an attatched prnound then slice the pronoun and check again\n",
    "\n",
    "\n",
    "df = result_df.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     ayah_index = row['tokinized_text'].index(harf_fi)\n",
    "#     print(row['tokinized_text'][ayah_index], row['tokinized_text'][ayah_index+1])\n",
    "\n",
    "#     print([*row['tokinized_text'][ayah_index+1]][-1])\n",
    "\n",
    "#     if Tashkeels.KASRA.value == [*row['tokinized_text'][ayah_index+1]][-1]:\n",
    "#         print('end in kasra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /Users/hasnat/Library/Python/3.9/lib/python/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/hasnat/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in /Users/hasnat/Library/Python/3.9/lib/python/site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/hasnat/Library/Python/3.9/lib/python/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/hasnat/Library/Python/3.9/lib/python/site-packages (from nltk) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
